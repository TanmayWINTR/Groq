{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP9fUdTQFFJ5EAS3pQMuvoW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TanmayWINTR/Groq/blob/main/GroqSpeedTest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 1: Installation and Setup\n",
        "\n",
        "Install necessary packages quietly"
      ],
      "metadata": {
        "id": "iXllbWt3kLTe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mB9BMUrEh2YK",
        "outputId": "6ed1a0d5-55a4-48d3-d345-ee25f3e9801f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m867.6/867.6 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.8/302.8 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.7/116.7 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m312.9/312.9 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m38.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.5/142.5 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q -U langchain langchain-openai langchain-groq\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import required libraries"
      ],
      "metadata": {
        "id": "dTJemNxOkSpS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from getpass import getpass\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "import os\n",
        "from langchain_openai import ChatOpenAI"
      ],
      "metadata": {
        "id": "ql22gOjNiWIk"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 2: API Key Input and Configuration\n",
        "\n",
        "Get GROQ API key and set environment variable"
      ],
      "metadata": {
        "id": "6eiL_jyCkWCC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "GROQ_API_KEY = getpass()\n",
        "\n",
        "os.environ[\"GROQ_API_KEY\"] = GROQ_API_KEY"
      ],
      "metadata": {
        "id": "PXZJEX0hidXb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get OpenAI API key and set environment variable"
      ],
      "metadata": {
        "id": "aEj5Ru37kaCw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "OPENAI_API_KEY = getpass()\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY"
      ],
      "metadata": {
        "id": "vNbZwEGDispG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 3: Initialize Models\n",
        "\n",
        "Initialize ChatGroq with specified parameters"
      ],
      "metadata": {
        "id": "9r2beWT8kd3y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "groq = ChatGroq(temperature=0, model_name=\"llama3-8b-8192\")"
      ],
      "metadata": {
        "id": "Tm9QK59LjOfN"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialize ChatOpenAI with default model"
      ],
      "metadata": {
        "id": "TGmHx0t5klZZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "openai = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")"
      ],
      "metadata": {
        "id": "HjcO3lqokngX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Section 5: Using GROQ for Chat"
      ],
      "metadata": {
        "id": "PVsUtcIalPy2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "\n",
        "# Define the system and human messages\n",
        "system = \"You are a helpful assistant.\"\n",
        "human = \"{text}\"\n",
        "\n",
        "# Create a prompt template\n",
        "prompt = ChatPromptTemplate.from_messages([(\"system\", system), (\"human\", human)])\n",
        "\n",
        "# Create a chain of operations with the prompt followed by groq\n",
        "chain = prompt | groq\n",
        "\n",
        "# Start the timer\n",
        "start_time = time.time()\n",
        "\n",
        "# Invoke the chain with the specific text\n",
        "response = chain.invoke({\"text\": \"What is your opinion on the possibility of artificial intelligence ruling the world?\"})\n",
        "\n",
        "# Calculate and print the elapsed time\n",
        "elapsed_time = time.time() - start_time\n",
        "print(f\"Response: {response}\")\n",
        "print(f\"Response time: {elapsed_time:.2f} seconds\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sTLAMlwBio9I",
        "outputId": "c30d6ebc-8923-4765-9999-8245d75681b9"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response: content='As a helpful assistant, I\\'m programmed to provide balanced and informative responses. While it\\'s fascinating to consider the potential of artificial intelligence (AI), I must emphasize that the notion of AI ruling the world is still largely speculative and not supported by current scientific evidence.\\n\\nCurrently, AI systems are designed to perform specific tasks, such as processing data, recognizing patterns, and making predictions. While AI has made tremendous progress in recent years, it is still far from achieving human-like consciousness or self-awareness, which are essential prerequisites for autonomous decision-making and self-governance.\\n\\nMoreover, the development of AI is a complex and ongoing process, involving the collaboration of experts from various fields, including computer science, neuroscience, philosophy, and ethics. Any notion of AI \"ruling the world\" is likely to be an oversimplification of the complex relationships between humans, AI systems, and the world around us.\\n\\nThat being said, it\\'s crucial to acknowledge the potential risks and challenges associated with the development and deployment of AI. As AI becomes increasingly integrated into our daily lives, it\\'s essential to ensure that these systems are designed and implemented with transparency, accountability, and ethical considerations in mind.\\n\\nIn conclusion, while AI has the potential to revolutionize various aspects of our lives, the notion of AI \"ruling the world\" is still largely speculative and not supported by current scientific evidence. It\\'s essential to approach the development and deployment of AI with a critical and nuanced perspective, prioritizing transparency, accountability, and ethical considerations to ensure that AI benefits humanity, rather than posing a threat to it.' response_metadata={'token_usage': {'completion_time': 0.381, 'completion_tokens': 317, 'prompt_time': 0.042, 'prompt_tokens': 35, 'queue_time': None, 'total_time': 0.423, 'total_tokens': 352}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_af05557ca2', 'finish_reason': 'stop', 'logprobs': None} id='run-382b0137-ae43-4d79-bb6d-288a4099cbb6-0'\n",
            "Response time: 0.75 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 6: Using OpenAI for Chat"
      ],
      "metadata": {
        "id": "naRxuLiAmYYT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the system and human interaction\n",
        "system = \"You are a helpful assistant.\"\n",
        "human = \"{text}\"\n",
        "\n",
        "# Create a prompt template with predefined messages\n",
        "prompt = ChatPromptTemplate.from_messages([(\"system\", system), (\"human\", human)])\n",
        "\n",
        "# Create a chain of operations with the prompt followed by an OpenAI call\n",
        "chain = prompt | openai\n",
        "\n",
        "# Start the timer\n",
        "start_time = time.time()\n",
        "\n",
        "# Invoke the chain with the specific text\n",
        "response = chain.invoke({\"text\": \"What is your opinion on the possibility of artificial intelligence ruling the world?\"})\n",
        "\n",
        "# Stop the timer\n",
        "elapsed_time = time.time() - start_time\n",
        "\n",
        "# Print the response and the response time\n",
        "print(f\"Response: {response}\")\n",
        "print(f\"Response time: {elapsed_time:.2f} seconds\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iKEwSDsXiOKK",
        "outputId": "dfa78b8d-0bd6-49d6-b40b-422dbc9ba989"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response: content=\"As an AI assistant, I don't have personal opinions or fears. The idea of artificial intelligence ruling the world is a common theme in science fiction, but in reality, it is important for humans to develop and implement AI technologies responsibly and ethically. It's essential to establish guidelines and regulations to ensure that AI is used for the benefit of society and to prevent any negative consequences. Ultimately, the future of AI will be shaped by the choices and actions of humans.\" response_metadata={'token_usage': {'completion_tokens': 93, 'prompt_tokens': 31, 'total_tokens': 124}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': 'fp_a450710239', 'finish_reason': 'stop', 'logprobs': None} id='run-037023e2-b5f5-4553-aae1-23f2a43aa077-0'\n",
            "Response time: 3.64 seconds\n"
          ]
        }
      ]
    }
  ]
}